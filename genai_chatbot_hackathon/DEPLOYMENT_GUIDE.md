
# ğŸš€ GenAI KB Chatbot - Deployment Guide

## ğŸ“‚ Project Structure
```
genai_chatbot_hackathon/
â”œâ”€â”€ app.py                  # Flask backend (Chatbot logic)
â”œâ”€â”€ streamlit_app.py        # Streamlit frontend (Optional)
â”œâ”€â”€ pinecone_sample.py      # Vector upload to Pinecone
â”œâ”€â”€ kb_articles.json        # Sample KB articles
â”œâ”€â”€ requirements.txt        # Python dependencies
â”œâ”€â”€ .env                    # API keys and secrets
â””â”€â”€ README.md               # Project overview
```

---

## âš™ï¸ Step 1: Install Requirements
Create a virtual environment (optional but recommended):
```bash
python3 -m venv venv
source venv/bin/activate  # On Windows: venv\Scripts\activate
```

Install dependencies:
```bash
pip install -r requirements.txt
```

---

## ğŸ”‘ Step 2: Configure `.env`
Create a `.env` file in the root folder:
```
OPENAI_API_KEY=sk-your-openai-key
OPENAI_API_BASE=https://api.openai.com/v1
PINECONE_API_KEY=your-pinecone-api-key
PINECONE_ENVIRONMENT=your-pinecone-environment
```

---

## ğŸ“¥ Step 3: Populate Pinecone Vector Index
Run this to upload KB articles as vector embeddings:
```bash
python pinecone_sample.py
```
âœ… Output: `âœ… Pinecone index populated`

---

## ğŸŸ¢ Step 4: Start Flask Backend API
```bash
python app.py
```
API is available at:
```
http://localhost:5000/chat
```

âœ… Example Test Call:
```bash
curl -X POST http://localhost:5000/chat -H "Content-Type: application/json" -d '{"issue": "Disk usage high", "dry_run": true}'
```

---

## ğŸŒ Step 5 (Optional): Launch Streamlit Frontend
```bash
streamlit run streamlit_app.py
```
Accessible at: `http://localhost:8501`

---

## ğŸš€ Step 6 (Optional): Dockerize for Deployment
### Sample Dockerfile
```dockerfile
FROM python:3.9
WORKDIR /app
COPY . .
RUN pip install -r requirements.txt
CMD ["python", "app.py"]
```
Build & Run Docker:
```bash
docker build -t genai-chatbot .
docker run -p 5000:5000 genai-chatbot
```

---

## âœ… Hackathon Demo Checklist
| Feature                             | âœ… Status |
|-------------------------------------|----------|
| Dry-Run / Real Execution            | âœ… Ready |
| Vector Search (Pinecone)            | âœ… Ready |
| Risky Command Approval              | âœ… Ready |
| Real-time Streaming (Streamlit)     | âœ… Ready |
| OpenAI LLM                          | âœ… Ready |
| .env based secret management        | âœ… Ready |

---

## ğŸ“¢ Pro Tips for Hackathon Demo
- Emphasize `.env` based secure key handling
- Demo Dry-run mode before real execution
- Showcase Pinecone vector search vs plain keyword search
- Use Streamlit as a user-friendly interface
- Explain risky command approval checkpoint (`rm -rf`, `shutdown`, etc.)

---


